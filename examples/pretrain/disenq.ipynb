{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MySoftwares\\Anaconda\\envs\\data\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from EduNLP.Pretrain import DisenQTokenizer, train_disenqnet\n",
    "from EduNLP.Vector import DisenQModel, T2V\n",
    "from EduNLP.I2V import DisenQ\n",
    "from EduNLP.ModelZoo import load_items\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练自己的disenQNet模型\n",
    "## 1. 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../..\"\n",
    "\n",
    "data_dir = f\"{BASE_DIR}/tests/test_vec/test_data\"\n",
    "output_dir = f\"{BASE_DIR}/examples/test_model/data/disenq\"\n",
    "\n",
    "disen_data_train = load_items(f\"{data_dir}/disenq_train.json\")\n",
    "disen_data_test = load_items(f\"{data_dir}/disenq_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load vocab from ../../examples/test_model/data/disenq\\vocab.list\n",
      "load concept from ../../examples/test_model/data/disenq\\concept.list\n",
      "load word2vec from ../../examples/test_model/data/disenq\\wv.th\n",
      "processing raw data for QuestionDataset...\n",
      "vocab size: 6827\n",
      "concept size: 5\n",
      "load vocab from ../../examples/test_model/data/disenq\\vocab.list\n",
      "load concept from ../../examples/test_model/data/disenq\\concept.list\n",
      "load word2vec from ../../examples/test_model/data/disenq\\wv.th\n",
      "processing raw data for QuestionDataset...\n",
      "Start training the disenQNet...\n",
      "[Epoch  1] train loss: 1.5506\n",
      "[Epoch  2] train loss: 1.5952, eval loss: 1.6069\n",
      "[Epoch  3] train loss: 1.4762, eval loss: 1.4880\n",
      "[Epoch  4] train loss: 1.4437, eval loss: 1.4640\n",
      "[Epoch  5] train loss: 1.3889, eval loss: 1.4287\n",
      "[Epoch  6] train loss: 1.3368, eval loss: 1.3825\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DisenQTokenizer(max_length=250, tokenize_method=\"space\")\n",
    "\n",
    "train_params = {\n",
    "    \"epoch\": 5,\n",
    "    \"batch\": 64,\n",
    "    \"lr\": 1e-3,\n",
    "    \"step\": 20,\n",
    "    \"trim_min\": 2,\n",
    "\n",
    "    \"gamma\": 0.5,\n",
    "    \"warm_up\": 1,\n",
    "    \"adv\": 10,\n",
    "    \"hidden\": 128,\n",
    "    \"dropout\": 0.2,\n",
    "    \"pos_weight\": 1,\n",
    "    \"cp\": 1.5,\n",
    "    \"mi\": 1.0,\n",
    "    \"dis\": 2.0,\n",
    "\n",
    "    \"w2v_workers\": 1,\n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "data_formation = {\n",
    "    \"content\": \"content\",\n",
    "    \"knowledge\": \"knowledge\"\n",
    "}\n",
    "train_disenqnet(\n",
    "    disen_data_train,\n",
    "    tokenizer,\n",
    "    output_dir,\n",
    "    output_dir,\n",
    "    train_params=train_params,\n",
    "    test_items=disen_data_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128])\n",
      "torch.Size([2, 23, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "tokenizer_kwargs = {\n",
    "    \"tokenizer_config_dir\": output_dir,\n",
    "}\n",
    "i2v = DisenQ('disenq', 'disenq', output_dir, tokenizer_kwargs=tokenizer_kwargs, device=\"cuda\")\n",
    "\n",
    "test_items = [\n",
    "    {\"content\": \"10 米 的 (2/5) = 多少 米 的 (1/2),有 公 式\"},\n",
    "    {\"content\": \"10 米 的 (2/5) = 多少 米 的 (1/2),有 公 式 , 如 图 , 若 $x,y$ 满 足 约 束 条 件 公 式\"},\n",
    "]\n",
    "\n",
    "t_vec = i2v.infer_token_vector(test_items, key=lambda x: x[\"content\"])\n",
    "i_vec = i2v.infer_item_vector(test_items, key=lambda x: x[\"content\"], vector_type=\"k\")\n",
    "\n",
    "print(i_vec.shape) # == torch.Size([2, 128])\n",
    "print(t_vec.shape) # == torch.Size([2, 23, 128])\n",
    "\n",
    "t_vec = i2v.infer_token_vector(test_items[0], key=lambda x: x[\"content\"])\n",
    "i_vec = i2v.infer_item_vector(test_items[0], key=lambda x: x[\"content\"], vector_type=\"k\")\n",
    "\n",
    "print(i_vec.shape) # == torch.Size([1, 128])\n",
    "print(t_vec.shape) # == torch.Size([1, 11, 128])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "776957673adb719a00031a24ed5efd2fa5ce8a13405e5193f8d278edd3805d55"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
