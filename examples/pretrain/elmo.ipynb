{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from EduNLP.ModelZoo.rnn import ElmoLM\n",
    "from EduNLP.Pretrain import train_elmo, ElmoTokenizer\n",
    "from EduNLP.Vector import ElmoModel, T2V\n",
    "from EduNLP.I2V import Elmo, get_pretrained_i2v\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练自己的 Elmo 模型\n",
    "## 1. 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置你的数据路径和输出路径\n",
    "BASE_DIR = \"../..\"\n",
    "\n",
    "data_dir = f\"{BASE_DIR}/static/test_data\"\n",
    "output_dir = f\"{BASE_DIR}/data/pretrain_test_models/elmo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_data():\n",
    "    _data = []\n",
    "    data_path = os.path.join(data_dir, \"standard_luna_data.json\")\n",
    "    with open(data_path, encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            _data.append(json.loads(line))\n",
    "    return _data\n",
    "\n",
    "train_items = stem_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58bdcefd3ee4222b3e14d5bae8b5930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "d:\\Python\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde9c6892c5947e99a96d7c633a9e7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ../../data/pretrain_test_models/elmo/\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2.616, 'train_samples_per_second': 9.557, 'train_steps_per_second': 1.529, 'train_loss': 11.407695770263672, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../data/pretrain_test_models/elmo/'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义训练参数\n",
    "train_params = {\n",
    "  # \"emb_dim\": 128,\n",
    "  # \"hid_dim\": 256,\n",
    "  # \"batch_size\": 4,\n",
    "  # \"epochs\": 1,\n",
    "  # \"lr\": 5e-3,\n",
    "  # \"device\": None,\n",
    "  \n",
    "  \"num_train_epochs\": 1,\n",
    "  \"per_device_train_batch_size\": 8,\n",
    "  \"save_steps\": 50,\n",
    "  \"save_total_limit\": 2,\n",
    "  \"logging_steps\": 5,\n",
    "  \"gradient_accumulation_steps\": 1,\n",
    "  \"learning_rate\": 5e-4,\n",
    "}\n",
    "\n",
    "train_elmo(train_items, output_dir, train_params=train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = [\n",
    "    {'ques_content': '有公式$\\\\FormFigureID{wrong1?}$和公式$\\\\FormFigureBase64{wrong2?}$，\\\n",
    "            如图$\\\\FigureID{088f15ea-8b7c-11eb-897e-b46bfc50aa29}$,\\\n",
    "            若$x,y$满足约束条件$\\\\SIFSep$，则$z=x+7 y$的最大值为$\\\\SIFBlank$'},\n",
    "    {'ques_content': '如图$\\\\FigureID{088f15ea-8b7c-11eb-897e-b46bfc50aa29}$, \\\n",
    "            若$x,y$满足约束条件$\\\\SIFSep$，则$z=x+7 y$的最大值为$\\\\SIFBlank$'},\n",
    "    {'ques_content': \"已知集合$A=\\\\left\\\\{x \\\\mid x^2-3 x-4<0\\\\right\\\\}, \\\n",
    "            \\\\quad B=\\\\{-4,1,3,5\\\\}, \\\\quad$ 则$A \\\\cap B$的值为\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 直接加载令牌容器和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EduNLP, INFO] All the weights of ElmoLM were initialized from the model checkpoint at ../../data/pretrain_test_models/elmo/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElmoLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElmoLMOutput([('pred_forward',\n",
       "               tensor([[[ 0.0316,  0.0020,  0.0019,  ...,  0.0027,  0.0090,  0.0026],\n",
       "                        [-0.0137,  0.0537, -0.0166,  ...,  0.0321, -0.0004, -0.0132],\n",
       "                        [-0.0383,  0.0203,  0.0041,  ...,  0.0692,  0.0201, -0.0460],\n",
       "                        ...,\n",
       "                        [ 0.0666,  0.0501, -0.0172,  ..., -0.0606, -0.0963, -0.0174],\n",
       "                        [ 0.0620,  0.0210, -0.0251,  ..., -0.0247, -0.0686,  0.0461],\n",
       "                        [ 0.1763,  0.0575,  0.0478,  ...,  0.0165, -0.1325,  0.0375]],\n",
       "               \n",
       "                       [[ 0.0266,  0.0823,  0.0178,  ...,  0.0589,  0.0346,  0.0259],\n",
       "                        [ 0.0152,  0.0167,  0.0491,  ...,  0.0322,  0.0288, -0.0143],\n",
       "                        [ 0.0579, -0.0485, -0.0416,  ...,  0.0089,  0.0598,  0.0234],\n",
       "                        ...,\n",
       "                        [ 0.0528,  0.0004,  0.0037,  ...,  0.0575, -0.1175,  0.0571],\n",
       "                        [-0.0164,  0.1281,  0.0162,  ..., -0.0192, -0.0780,  0.0098],\n",
       "                        [ 0.0202,  0.1164,  0.0491,  ...,  0.0247,  0.0049,  0.0074]],\n",
       "               \n",
       "                       [[ 0.0107,  0.0369,  0.0278,  ...,  0.0427,  0.0350,  0.0074],\n",
       "                        [-0.0428, -0.0061, -0.0049,  ...,  0.0074,  0.0845, -0.0277],\n",
       "                        [ 0.0449, -0.0344, -0.0046,  ...,  0.0831,  0.0623, -0.0191],\n",
       "                        ...,\n",
       "                        [ 0.0277, -0.0344,  0.0222,  ..., -0.0287,  0.0387, -0.0176],\n",
       "                        [ 0.0529,  0.0354, -0.1125,  ...,  0.0049, -0.0274, -0.0475],\n",
       "                        [ 0.0402,  0.0458, -0.0009,  ...,  0.0300,  0.0192, -0.0788]]],\n",
       "                      grad_fn=<AddBackward0>)),\n",
       "              ('pred_backward',\n",
       "               tensor([[[ 0.0595,  0.0858,  0.0590,  ...,  0.0149,  0.0144, -0.0359],\n",
       "                        [ 0.0468,  0.0529,  0.0031,  ...,  0.0663,  0.0417, -0.0522],\n",
       "                        [ 0.0571,  0.0408, -0.0243,  ...,  0.0168,  0.0212,  0.0391],\n",
       "                        ...,\n",
       "                        [ 0.0566, -0.0023,  0.0537,  ...,  0.1341,  0.0298, -0.0442],\n",
       "                        [ 0.0429,  0.0382,  0.0851,  ...,  0.1060, -0.0449, -0.0491],\n",
       "                        [ 0.0220,  0.0621,  0.0689,  ...,  0.0446,  0.0415, -0.0047]],\n",
       "               \n",
       "                       [[ 0.0831,  0.1315, -0.0388,  ...,  0.0710, -0.0292,  0.0572],\n",
       "                        [ 0.0870,  0.0864, -0.0192,  ...,  0.0553, -0.0441,  0.0025],\n",
       "                        [ 0.1099,  0.0093,  0.0136,  ...,  0.0782, -0.0483,  0.0469],\n",
       "                        ...,\n",
       "                        [ 0.1023,  0.0868,  0.0978,  ...,  0.1087,  0.0924,  0.0262],\n",
       "                        [ 0.0194,  0.1390,  0.0845,  ...,  0.0980,  0.0592, -0.0138],\n",
       "                        [ 0.0554,  0.0525,  0.0910,  ...,  0.0106,  0.0252, -0.0314]],\n",
       "               \n",
       "                       [[ 0.0125,  0.0665, -0.0685,  ...,  0.0386,  0.0531,  0.0622],\n",
       "                        [ 0.0578,  0.0608, -0.0307,  ...,  0.0903,  0.1038,  0.0599],\n",
       "                        [ 0.0586,  0.0203, -0.0047,  ...,  0.0807,  0.0362, -0.0178],\n",
       "                        ...,\n",
       "                        [ 0.0283,  0.0254, -0.0292,  ...,  0.1130,  0.0709,  0.0208],\n",
       "                        [-0.0120,  0.0255,  0.0277,  ...,  0.0895,  0.0367,  0.0328],\n",
       "                        [ 0.0323,  0.0860,  0.0543,  ...,  0.0128,  0.0392,  0.0042]]],\n",
       "                      grad_fn=<AddBackward0>)),\n",
       "              ('forward_output',\n",
       "               tensor([[[-0.0490, -0.0493, -0.0498,  ...,  0.0861,  0.0404, -0.0043],\n",
       "                        [-0.0944, -0.0000, -0.0000,  ...,  0.0000,  0.0590,  0.0554],\n",
       "                        [-0.1086, -0.0000, -0.1545,  ...,  0.1166,  0.0536, -0.0000],\n",
       "                        ...,\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.3207, -0.0000,  0.0284],\n",
       "                        [ 0.0000,  0.0311,  0.1903,  ...,  0.3098, -0.0000,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.1623,  ...,  0.0000, -0.0000, -0.0132]],\n",
       "               \n",
       "                       [[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0108, -0.1189],\n",
       "                        [-0.0000, -0.0000, -0.0000,  ..., -0.0169, -0.0374, -0.0000],\n",
       "                        [-0.0000, -0.0511, -0.1040,  ...,  0.0021, -0.0000, -0.0000],\n",
       "                        ...,\n",
       "                        [ 0.0000,  0.0377,  0.2006,  ...,  0.0000, -0.0241,  0.0000],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.3099, -0.0000,  0.0143],\n",
       "                        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0163, -0.0000]],\n",
       "               \n",
       "                       [[ 0.0064, -0.0000, -0.0000,  ...,  0.0006,  0.0000, -0.0000],\n",
       "                        [-0.0511, -0.0318,  0.0434,  ...,  0.0011,  0.0012, -0.0000],\n",
       "                        [-0.0000, -0.1041,  0.0255,  ...,  0.0000, -0.0000, -0.2039],\n",
       "                        ...,\n",
       "                        [ 0.1047, -0.0000, -0.0000,  ...,  0.0890, -0.0000, -0.1702],\n",
       "                        [ 0.0241, -0.0000, -0.1872,  ...,  0.1555,  0.0000, -0.2131],\n",
       "                        [-0.0000, -0.0795, -0.1944,  ...,  0.2061,  0.0422, -0.0537]]],\n",
       "                      grad_fn=<MulBackward0>)),\n",
       "              ('backward_output',\n",
       "               tensor([[[ 0.0000,  0.0000, -0.0647,  ..., -0.0000,  0.0000, -0.1787],\n",
       "                        [ 0.0000,  0.1810, -0.0197,  ..., -0.0000,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0043,  ..., -0.2202,  0.1272, -0.0000],\n",
       "                        ...,\n",
       "                        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.1446, -0.0723],\n",
       "                        [-0.0000, -0.0572, -0.0000,  ..., -0.0000, -0.0000, -0.0494],\n",
       "                        [-0.0000, -0.0085, -0.0200,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "               \n",
       "                       [[ 0.0000,  0.1195, -0.0313,  ..., -0.1743,  0.1179, -0.2065],\n",
       "                        [ 0.1000,  0.0000, -0.0691,  ..., -0.0943,  0.0000, -0.0000],\n",
       "                        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.1264],\n",
       "                        ...,\n",
       "                        [-0.0464, -0.0000, -0.0667,  ..., -0.1095, -0.0000, -0.0723],\n",
       "                        [-0.0000, -0.0000, -0.0468,  ..., -0.1018, -0.1118, -0.0000],\n",
       "                        [-0.0308, -0.0000, -0.0200,  ..., -0.0742, -0.0000, -0.0000]],\n",
       "               \n",
       "                       [[-0.0000,  0.0000, -0.0174,  ..., -0.0000,  0.0028, -0.0000],\n",
       "                        [-0.0185,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "                        [-0.0000,  0.0383, -0.0501,  ..., -0.0203, -0.1739, -0.1748],\n",
       "                        ...,\n",
       "                        [-0.0000,  0.1043, -0.0000,  ..., -0.0507, -0.0000, -0.0158],\n",
       "                        [-0.0000,  0.0000, -0.0000,  ..., -0.1891, -0.0000, -0.0000],\n",
       "                        [ 0.0338,  0.0872, -0.0326,  ..., -0.1289,  0.0255, -0.0000]]],\n",
       "                      grad_fn=<MulBackward0>))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_dir = output_dir\n",
    "\n",
    "model = ElmoLM.from_pretrained(pretrained_model_dir)\n",
    "tokenizer = ElmoTokenizer.from_pretrained(pretrained_model_dir)\n",
    "\n",
    "encodes = tokenizer(test_items, lambda x: x['ques_content'])\n",
    "model(**encodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 使用 I2V 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EduNLP, INFO] All the weights of ElmoLM were initialized from the model checkpoint at ../../data/pretrain_test_models/elmo/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElmoLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 600])\n",
      "torch.Size([1, 17, 600])\n",
      "torch.Size([3, 600])\n",
      "torch.Size([3, 40, 600])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\EduNLP\\Vector\\elmo_vec.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (outputs.forward_output[torch.arange(len(items[\"seq_len\"])), torch.tensor(items[\"seq_len\"]) - 1],\n"
     ]
    }
   ],
   "source": [
    "tokenizer_kwargs = {\"tokenizer_config_dir\": pretrained_model_dir}\n",
    "i2v = Elmo('elmo', 'elmo', output_dir, tokenizer_kwargs=tokenizer_kwargs)\n",
    "\n",
    "# 可以对单个题目进行表征\n",
    "i_vec, t_vec = i2v(test_items[0], key=lambda x: x[\"ques_content\"])\n",
    "print(i_vec.shape) # == torch.Size([x])\n",
    "print(t_vec.shape) # == torch.Size([x, x])\n",
    "\n",
    "# 也可以对题目列表进行表征\n",
    "i_vec, t_vec = i2v(test_items, key=lambda x: x[\"ques_content\"])\n",
    "print(i_vec.shape) # == torch.Size([len(test_items), x])\n",
    "print(t_vec.shape) # == torch.Size([len(test_items), x, x]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 使用 Tokenizer 和 T2V 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EduNLP, INFO] All the weights of ElmoLM were initialized from the model checkpoint at ../../data/pretrain_test_models/elmo/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElmoLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 600])\n",
      "\n",
      "torch.Size([3, 600])\n",
      "torch.Size([3, 40, 600])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载之前训练的模型 tokenizer\n",
    "tokenizer = ElmoTokenizer.from_pretrained(pretrained_model_dir)\n",
    "encodes = tokenizer(test_items, key=lambda x: x['ques_content'])\n",
    "\n",
    "t2v = ElmoModel(pretrained_model_dir)\n",
    "\n",
    "i_vec = t2v(encodes)\n",
    "print(i_vec.shape) # == torch.Size([len(test_items), x])\n",
    "print()\n",
    "\n",
    "i_vec = t2v.infer_vector(encodes)\n",
    "t_vec = t2v.infer_tokens(encodes)\n",
    "print(i_vec.shape) # == torch.Size([len(test_items), x])\n",
    "print(t_vec.shape) # == torch.Size([len(test_items), x, x]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 使用 EduNLP 中公开的预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='modelhub-backend-269-production.env.bdaa.pro', port=443): Max retries exceeded with url: /v1/api/getPretrainedModelList (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py:700\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[39mif\u001b[39;00m is_new_proxy_conn \u001b[39mand\u001b[39;00m http_tunnel_required:\n\u001b[1;32m--> 700\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py:996\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    994\u001b[0m     conn\u001b[39m.\u001b[39mtls_in_tls_required \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 996\u001b[0m conn\u001b[39m.\u001b[39;49mconnect()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\connection.py:364\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls_in_tls_required:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect_tls_proxy(hostname, conn)\n\u001b[0;32m    365\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\connection.py:499\u001b[0m, in \u001b[0;36mHTTPSConnection._connect_tls_proxy\u001b[1;34m(self, hostname, conn)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39m# If no cert was provided, use only the default options for server\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m# certificate validation\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m socket \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    500\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    501\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    502\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    503\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    504\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mhostname,\n\u001b[0;32m    505\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mssl_context,\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m ssl_context\u001b[39m.\u001b[39mverify_mode \u001b[39m!=\u001b[39m ssl\u001b[39m.\u001b[39mCERT_NONE \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[0;32m    509\u001b[0m     ssl_context, \u001b[39m\"\u001b[39m\u001b[39mcheck_hostname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    510\u001b[0m ):\n\u001b[0;32m    511\u001b[0m     \u001b[39m# While urllib3 attempts to always turn off hostname matching from\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[39m# the TLS library, this cannot always be done. So we check whether\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[39m# the TLS Library still thinks it's matching hostnames.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py:453\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n\u001b[0;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\util\\ssl_.py:495\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock)\n",
      "File \u001b[1;32md:\\Python\\lib\\ssl.py:512\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    507\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    510\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    513\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    514\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    515\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    516\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    517\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    518\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    519\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    520\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\lib\\ssl.py:1070\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1070\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1071\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Python\\lib\\ssl.py:1341\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1341\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1342\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:997)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='modelhub-backend-269-production.env.bdaa.pro', port=443): Max retries exceeded with url: /v1/api/getPretrainedModelList (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [85], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 获取公开的预训练模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pretrained_dir \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mBASE_DIR\u001b[39m}\u001b[39;00m\u001b[39m/examples/test_model/elmo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m i2v \u001b[39m=\u001b[39m get_pretrained_i2v(\u001b[39m\"\u001b[39m\u001b[39melmo_pp\u001b[39m\u001b[39m\"\u001b[39m, model_dir\u001b[39m=\u001b[39mpretrained_dir)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\EduNLP\\I2V\\i2v.py:545\u001b[0m, in \u001b[0;36mget_pretrained_i2v\u001b[1;34m(name, model_dir)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pretrained_i2v\u001b[39m(name, model_dir\u001b[39m=\u001b[39mMODEL_DIR):\n\u001b[0;32m    513\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m    It is a good idea if you want to switch item to vector earily.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39m    ([array([ ...dtype=float32)], None)\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m     pretrained_models \u001b[39m=\u001b[39m get_all_pretrained_models()\n\u001b[0;32m    546\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pretrained_models:\n\u001b[0;32m    547\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnknown model name \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, use one of the provided models: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (name, \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(pretrained_models))\n\u001b[0;32m    549\u001b[0m         )\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\EduNLP\\Vector\\t2v.py:89\u001b[0m, in \u001b[0;36mget_all_pretrained_models\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_all_pretrained_models\u001b[39m():\n\u001b[0;32m     88\u001b[0m     url \u001b[39m=\u001b[39m MODELHUB_URL \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgetPretrainedModelList\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 89\u001b[0m     r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[0;32m     90\u001b[0m     \u001b[39massert\u001b[39;00m r\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m, r\u001b[39m.\u001b[39mstatus_code\n\u001b[0;32m     91\u001b[0m     r \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(r\u001b[39m.\u001b[39mcontent)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\requests\\adapters.py:563\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='modelhub-backend-269-production.env.bdaa.pro', port=443): Max retries exceeded with url: /v1/api/getPretrainedModelList (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))"
     ]
    }
   ],
   "source": [
    "# 获取公开的预训练模型\n",
    "pretrained_dir = f\"{BASE_DIR}/examples/test_model/elmo\"\n",
    "i2v = get_pretrained_i2v(\"elmo_pp\", model_dir=pretrained_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_vec, t_vec = i2v(test_items)\n",
    "print(i_vec.shape)\n",
    "print(t_vec.shape)\n",
    "print()\n",
    "\n",
    "# 也可以单独获取题目表征和各个token的表征\n",
    "i_vec = i2v.infer_item_vector(test_items, key=lambda x: x['ques_content'])\n",
    "print(i_vec.shape)\n",
    "t_vec = i2v.infer_token_vector(test_items, key=lambda x: x['ques_content'])\n",
    "print(t_vec.shape)\n",
    "print()\n",
    "\n",
    "# 同样，可以获取单个题目的表征\n",
    "i_vec, t_vec = i2v(test_items[0], key=lambda x: x['ques_content'])\n",
    "print(i_vec.shape)\n",
    "print(t_vec.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
