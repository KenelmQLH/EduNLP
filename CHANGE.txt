v0.0.9
    1. Refactor tokenizer Basic Tokenizer and Pretrained Tokenizer
    2. Refactor model structures following huggingface styles for Elmo, BERT, DisenQNet and QuesNet
    3. Add PreprocessingPipeline and Pipeline
    4. Add downstream task: knowledge prediction and property prediction
    5. Fix a bug in RNN which causes ELMo not converging
    6. Move all the test models to modelhub
    7. Update test data files

v0.0.8
    1. add Emlo
    2. add DisenQNet
    3. add QuesNet
    4. add tal-edu-bert
    5. add dynamic mapping table from modelhub
    6. fix cuda error
    7. update pretrained models

v0.0.7:
    1. add BERT and pretrained model (luna_bert)
    2. speed up the process in sif
    3. handling OOV in word2vec
    4. add English tutorials
    5. add api docs and prettify tutorials
    6. fix the np.error in gensim_vec.W2V.infer_vector
    7. fix the parameters lost in tokenization

v0.0.6:
    1. dev: add half-pretrained rnn model
    2. important!!!: rename TextTokenizer to PureTextTokenizer, and add a new tokenizer named TextTokenizer (the two have similar but not the same behaviours).
    3. sif: add $\textf{}$ syntax
    4. add two pretrained w2v model: w2v_sci_300 and w2v_lit_300

v0.0.5:
    1. fix the missing stopwords.txt when use pip install

v0.0.4:
    1. fix the project errors

v0.0.3:
    1. update formula ast: supporting more symbols and functions defined in katex
    2. add tokens to vector tools, including word2vec and doc2vec using gensim
    3. sci4sif support tokenization grouped by segments
    4. add special tokens: \SIFTag and \SIFSep
    5. add item to vector tools
    6. add interface for getting pretrained models, where the supported model names can be accessed by `edunlp i2v` in the command console

v0.0.2:
    1. fix potential ModuleNotFoundError

v0.0.1:
    1. Add Formula class to parse latex formula, which will generate the abstract syntax tree.
    2. Add SIF v0.0.2.
    3. Add sif4sci function which serves as a preprocess function for downstream tasks.
